{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad48fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENIUS_TOKEN = \"CYylC51NBQe_zpK-nXJ0P6fWOqDs7vjpq_uUvDr5BCRF7NBfFJMjz-sohJQ3A4wH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d790f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "from itertools import combinations\n",
    "from collections import Counter, defaultdict\n",
    "from wordcloud import WordCloud\n",
    "from bs4 import BeautifulSoup\n",
    "import lyricsgenius\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1134a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960s:    9 noder  |     15 kanter\n",
      "1970s:    5 noder  |      7 kanter\n",
      "1980s:    2 noder  |      1 kanter\n",
      "1990s:   78 noder  |   1143 kanter\n",
      "2000s:  195 noder  |   5959 kanter\n",
      "2010s:  137 noder  |   2682 kanter\n",
      "2020s:   73 noder  |    568 kanter\n"
     ]
    }
   ],
   "source": [
    "songs = pd.read_csv('../../datadump/songs_no_dublicates.csv',\n",
    "                    usecols=['recording_mbid','first_release_year','artist_mbid'])\n",
    "writes = pd.read_csv('../../datadump/writerships.csv',\n",
    "                     usecols=['recording_mbid','writer_id'])\n",
    "\n",
    "# Sørg for kun den tidligste udgivelse per recording\n",
    "songs = (songs\n",
    "         .sort_values('first_release_year')\n",
    "         .drop_duplicates('recording_mbid', keep='first'))\n",
    "\n",
    "# ─── 1) Beregn peak‐decade per artist ───────────────────────────────\n",
    "# A) tilføj decade‐kolonne for hver sang\n",
    "songs['decade'] = (songs.first_release_year // 10) * 10\n",
    "\n",
    "# B) tæl sange per artist × decade\n",
    "adc = (\n",
    "    songs\n",
    "    .groupby(['artist_mbid','decade'])\n",
    "    .size()\n",
    "    .reset_index(name='count')\n",
    ")\n",
    "# C) find for hver artist den decade med max count\n",
    "idx = adc.groupby('artist_mbid')['count'].idxmax()\n",
    "artist_decade_map = (\n",
    "    adc\n",
    "    .loc[idx, ['artist_mbid','decade']]\n",
    "    .set_index('artist_mbid')['decade']\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "\n",
    "# ─── 2) Funktion der bygger artist–artist‐graf for et givent årti ──\n",
    "def build_artist_graph_peak(decade_start):\n",
    "    decade_end = decade_start + 9\n",
    "\n",
    "    # A) vælg kun sange i det tiår\n",
    "    dec_songs = songs[\n",
    "        songs['first_release_year'].between(decade_start, decade_end) &\n",
    "        (songs['artist_mbid'].map(artist_decade_map) == decade_start)\n",
    "    ]\n",
    "    rec2art = dict(zip(dec_songs.recording_mbid, dec_songs.artist_mbid))\n",
    "\n",
    "    # B) filtrer writerships\n",
    "    writes_sub = writes[writes.recording_mbid.isin(rec2art)]\n",
    "\n",
    "    # C) akkumuler artist‐par pr. writer og husk writers\n",
    "    pair_counter = Counter()\n",
    "    edge_writers = defaultdict(set)\n",
    "    for writer_id, grp in writes_sub.groupby('writer_id'):\n",
    "        artists = sorted({ rec2art[r] for r in grp.recording_mbid })\n",
    "        if len(artists) < 2:\n",
    "            continue\n",
    "        for a1, a2 in combinations(artists, 2):\n",
    "            pair_counter[(a1, a2)] += 1\n",
    "            edge_writers[(a1, a2)].add(writer_id)\n",
    "\n",
    "    # D) byg graf med vægt og writer-liste\n",
    "    G = nx.Graph()\n",
    "    for (a1, a2), w in pair_counter.items():\n",
    "        G.add_edge(a1, a2,\n",
    "                   weight=w,\n",
    "                   writers=list(edge_writers[(a1, a2)]))\n",
    "    return G\n",
    "\n",
    "\n",
    "# ─── 3) Eksempel: byg grafer for 1960s–2020s og print stats ─────────\n",
    "artist_graphs_peak = {}\n",
    "for start in range(1960, 2030, 10):\n",
    "    label = f\"{start}s\"\n",
    "    G = build_artist_graph_peak(start)\n",
    "    artist_graphs_peak[label] = G\n",
    "    print(f\"{label}: {G.number_of_nodes():>4} noder  | {G.number_of_edges():>6} kanter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb954d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Indlæs artist‐lookup og byg dict: artist_mbid → navn\n",
    "artist_lookup = pd.read_csv('../../datadump/artists_all.csv',\n",
    "                           usecols=['artist_mbid','name'],\n",
    "                           dtype=str)\n",
    "artist_dict = artist_lookup.set_index('artist_mbid')['name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f25efa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"../../public/flest_udgivelser\"\n",
    "output_dir = \"../../public/flest_udgivelser_csv\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(input_dir, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        decade = filename.replace(\".json\", \"\")\n",
    "        output_path = os.path.join(output_dir, f\"{decade}.csv\")\n",
    "\n",
    "        with open(output_path, \"w\", newline=\"\", encoding=\"utf-8\") as out:\n",
    "            writer = csv.writer(out)\n",
    "            writer.writerow([\"artist_mbid\", \"artist_name\", \"community\"])\n",
    "            for node in data[\"nodes\"]:\n",
    "                writer.writerow([node[\"id\"], node[\"name\"], node[\"community\"]])\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def load_communities_from_csv(folder):\n",
    "    decade2comm = {}\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            match = re.search(r\"(\\d{4}s)\", filename)  # matcher fx '1960s'\n",
    "            if not match:\n",
    "                continue\n",
    "            decade = match.group(1)\n",
    "\n",
    "            df = pd.read_csv(os.path.join(folder, filename))\n",
    "            comm2nodes = defaultdict(list)\n",
    "            for _, row in df.iterrows():\n",
    "                comm2nodes[row[\"community\"]].append(row[\"artist_mbid\"])\n",
    "            decade2comm[decade] = comm2nodes\n",
    "    return decade2comm\n",
    "\n",
    "all_comm2nodes_peak = load_communities_from_csv(\"../../public/flest_udgivelser_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcd8c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tjekker community data for 1960s...\n",
      " → Fundet 2 communities\n",
      "\n",
      "Tjekker community data for 1970s...\n",
      " → Fundet 2 communities\n",
      "\n",
      "Tjekker community data for 1980s...\n",
      " → Fundet 1 communities\n",
      "\n",
      "Tjekker community data for 1990s...\n",
      " → Fundet 4 communities\n",
      "\n",
      "Tjekker community data for 2000s...\n",
      " → Fundet 4 communities\n",
      "\n",
      "Tjekker community data for 2010s...\n",
      " → Fundet 3 communities\n",
      "\n",
      "Tjekker community data for 2020s...\n",
      " → Fundet 3 communities\n"
     ]
    }
   ],
   "source": [
    "for decade, G in artist_graphs_peak.items():\n",
    "    print(f\"\\nTjekker community data for {decade}...\")\n",
    "    comm2nodes = all_comm2nodes_peak.get(decade, {})\n",
    "    print(f\" → Fundet {len(comm2nodes)} communities\")\n",
    "    if not comm2nodes:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a53647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ Behandler 1960s_comm0: 5 artister\n",
      "   ✅ Gemt 7 lyrics i community_lyrics_ovh/1960s_comm0_lyrics.csv\n",
      "\n",
      "▶ Behandler 1960s_comm1: 4 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/1960s_comm1_lyrics.csv\n",
      "\n",
      "▶ Behandler 1970s_comm0: 2 artister\n",
      "   ✅ Gemt 0 lyrics i community_lyrics_ovh/1970s_comm0_lyrics.csv\n",
      "\n",
      "▶ Behandler 1970s_comm1: 3 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/1970s_comm1_lyrics.csv\n",
      "\n",
      "▶ Behandler 1980s_comm0: 2 artister\n",
      "   ✅ Gemt 2 lyrics i community_lyrics_ovh/1980s_comm0_lyrics.csv\n",
      "\n",
      "▶ Behandler 1990s_comm0: 21 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/1990s_comm0_lyrics.csv\n",
      "\n",
      "▶ Behandler 1990s_comm1: 41 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/1990s_comm1_lyrics.csv\n",
      "\n",
      "▶ Behandler 1990s_comm2: 8 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/1990s_comm2_lyrics.csv\n",
      "\n",
      "▶ Behandler 1990s_comm3: 8 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/1990s_comm3_lyrics.csv\n",
      "\n",
      "▶ Behandler 2000s_comm1: 14 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2000s_comm1_lyrics.csv\n",
      "\n",
      "▶ Behandler 2000s_comm3: 61 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2000s_comm3_lyrics.csv\n",
      "\n",
      "▶ Behandler 2000s_comm0: 38 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2000s_comm0_lyrics.csv\n",
      "\n",
      "▶ Behandler 2000s_comm2: 82 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2000s_comm2_lyrics.csv\n",
      "\n",
      "▶ Behandler 2010s_comm0: 67 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2010s_comm0_lyrics.csv\n",
      "\n",
      "▶ Behandler 2010s_comm2: 58 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2010s_comm2_lyrics.csv\n",
      "\n",
      "▶ Behandler 2010s_comm1: 12 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2010s_comm1_lyrics.csv\n",
      "\n",
      "▶ Behandler 2020s_comm0: 16 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2020s_comm0_lyrics.csv\n",
      "\n",
      "▶ Behandler 2020s_comm1: 31 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2020s_comm1_lyrics.csv\n",
      "\n",
      "▶ Behandler 2020s_comm2: 26 artister\n",
      "   ✅ Gemt 20 lyrics i community_lyrics_ovh/2020s_comm2_lyrics.csv\n"
     ]
    }
   ],
   "source": [
    "CANDIDATE_SONGS = 40\n",
    "TARGET_LYRICS   = 20\n",
    "DATADIR         = \"../../datadump\"\n",
    "OUT_DIR         = \"community_lyrics_ovh\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "id_to_name = artists.set_index('artist_mbid')['name'].to_dict()\n",
    "\n",
    "# ─── 3) HJÆLPEFUNKTIONER ──────────────────────────────────────────────────────\n",
    "def fetch_lyrics_ovh(artist: str, title: str) -> str:\n",
    "    url = f\"https://api.lyrics.ovh/v1/{requests.utils.quote(artist)}/{requests.utils.quote(title)}\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=5)\n",
    "        if r.status_code == 200:\n",
    "            return r.json().get(\"lyrics\", \"\")\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "def clean_lyrics(text: str) -> str:\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "    text = re.sub(r\"^[A-Za-z0-9 ]+:\\s*\", \"\", text, flags=re.MULTILINE)\n",
    "    lines = [ln.strip() for ln in text.splitlines() if ln.strip()]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ─── 4) LOOP OVER COMMUNITIES & HENT LYRICS ─────────────────────────────────\n",
    "for decade, G in artist_graphs_peak.items():\n",
    "    comm2nodes = all_comm2nodes_peak.get(decade, {})\n",
    "    if not comm2nodes:\n",
    "        continue\n",
    "\n",
    "    for comm_id, members in comm2nodes.items():\n",
    "        label = f\"{decade}_comm{comm_id}\"\n",
    "        print(f\"\\n▶ Behandler {label}: {len(members)} artister\")\n",
    "\n",
    "        # A) Byg per‐artist liste over “forbundne” writers\n",
    "        eligible_writers = defaultdict(set)\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            if u in members and v in members and \"writers\" in data:\n",
    "                for w in data[\"writers\"]:\n",
    "                    eligible_writers[u].add(w)\n",
    "                    eligible_writers[v].add(w)\n",
    "\n",
    "        # B) Filtrér sange\n",
    "        df = (\n",
    "            writes\n",
    "            .merge(songs[['recording_mbid','title','artist_mbid']],\n",
    "                   on='recording_mbid', how='inner')\n",
    "        )\n",
    "        df = df[df['artist_mbid'].isin(members)]\n",
    "        mask = df.apply(lambda row: row['writer_id'] in eligible_writers[row['artist_mbid']], axis=1)\n",
    "        df = df[mask]\n",
    "\n",
    "        df_songs = df[['recording_mbid','title','artist_mbid']].drop_duplicates('recording_mbid')\n",
    "        if df_songs.empty:\n",
    "            print(\"   ⚠ Ingen sange opfylder de nye, skærpede kriterier – springer over.\")\n",
    "            continue\n",
    "\n",
    "        # C) Hent lyrics løbende indtil vi har 20\n",
    "        rows = []\n",
    "        seen_recordings = set()\n",
    "        while len(rows) < TARGET_LYRICS and len(seen_recordings) < len(df_songs):\n",
    "            remaining = df_songs[~df_songs['recording_mbid'].isin(seen_recordings)]\n",
    "            if remaining.empty:\n",
    "                break\n",
    "            row = remaining.sample(n=1, random_state=int(time.time())).iloc[0]\n",
    "            seen_recordings.add(row['recording_mbid'])\n",
    "\n",
    "            artist_name = id_to_name.get(row['artist_mbid'], \"\")\n",
    "            title_clean = re.sub(r\"\\s*\\(.*?\\)\", \"\", row['title']).strip()\n",
    "            raw = fetch_lyrics_ovh(artist_name, title_clean)\n",
    "            lyric = clean_lyrics(raw)\n",
    "            if lyric:\n",
    "                rows.append({\n",
    "                    \"recording_mbid\": row[\"recording_mbid\"],\n",
    "                    \"title\":          row[\"title\"],\n",
    "                    \"artist_name\":    artist_name,\n",
    "                    \"lyrics\":         lyric\n",
    "                })\n",
    "            time.sleep(1)\n",
    "\n",
    "        # D) Gem lyrics\n",
    "        out = pd.DataFrame(rows)\n",
    "        path = os.path.join(OUT_DIR, f\"{label}_lyrics.csv\")\n",
    "        out.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "        print(f\"   ✅ Gemt {len(rows)} lyrics i {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f52f3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file with no data: 1970s_comm0_lyrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LYRICS_DIR = \"community_lyrics_ovh\"\n",
    "OUT_WC_FREQ = \"wordclouds_frequency\"\n",
    "os.makedirs(OUT_WC_FREQ, exist_ok=True)\n",
    "\n",
    "# indlæs alle community‐filer\n",
    "for fname in os.listdir(LYRICS_DIR):\n",
    "    if not fname.endswith(\"_lyrics.csv\"):\n",
    "        continue\n",
    "    label = fname.replace(\"_lyrics.csv\",\"\")\n",
    "    file_path = os.path.join(LYRICS_DIR, fname)\n",
    "    if os.stat(file_path).st_size == 0:\n",
    "        print(f\"Skipping empty file: {fname}\")\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Skipping file with no data: {fname}\")\n",
    "        continue\n",
    "    # slå alle lyrics sammen til ét dokument\n",
    "    text = \"\\n\".join(df[\"lyrics\"].fillna(\"\"))\n",
    "    # rens kun alfanumerisk\n",
    "    tokens = re.findall(r\"\\b\\w{3,}\\b\", text.lower())\n",
    "    freq = Counter(tokens)\n",
    "    common = {w:c for w,c in freq.most_common(100)}\n",
    "    # lav cloud\n",
    "    wc = WordCloud(width=800, height=400, background_color=\"white\")\\\n",
    "         .generate_from_frequencies(common)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Frequency WordCloud: {label}\")\n",
    "    plt.savefig(f\"{OUT_WC_FREQ}/{label}_freq.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4005a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping file with no data: 1970s_comm0_lyrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "LYRICS_DIR = \"community_lyrics_ovh\"\n",
    "OUT_WC_TFIDF = \"wordclouds_tfidf\"\n",
    "os.makedirs(OUT_WC_TFIDF, exist_ok=True)\n",
    "\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "STOP = stopwords.words(\"english\")\n",
    "\n",
    "for fname in os.listdir(LYRICS_DIR):\n",
    "    if not fname.endswith(\"_lyrics.csv\"): continue\n",
    "    label = fname.replace(\"_lyrics.csv\",\"\")\n",
    "    file_path = os.path.join(LYRICS_DIR, fname)\n",
    "    if os.stat(file_path).st_size == 0:\n",
    "        print(f\"Skipping empty file: {fname}\")\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Skipping file with no data: {fname}\")\n",
    "        continue\n",
    "    docs = df[\"lyrics\"].fillna(\"\").tolist()\n",
    "\n",
    "    # simpel rens og stop‐liste\n",
    "    def clean(txt):\n",
    "        txt = re.sub(r\"[^\\w\\s]\",\" \", txt.lower())\n",
    "        return txt\n",
    "\n",
    "    docs = [clean(d) for d in docs]\n",
    "    vec = TfidfVectorizer(stop_words=STOP,\n",
    "                          max_features=50,\n",
    "                          token_pattern=r\"(?u)\\b\\w\\w+\\b\")\n",
    "    X = vec.fit_transform(docs)\n",
    "    terms = vec.get_feature_names_out()\n",
    "    scores = X.sum(axis=0).A1\n",
    "    freqs = dict(zip(terms, scores))\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, background_color=\"white\")\\\n",
    "         .generate_from_frequencies(freqs)\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"TF–IDF WordCloud: {label}\")\n",
    "    plt.savefig(f\"{OUT_WC_TFIDF}/{label}_tfidf.png\", dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fde7f62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  decade  n_nodes  n_edges  avg_degree   density  avg_clust  n_comps  \\\n",
      "0  1960s        9       15    3.333333  0.416667   0.172758        1   \n",
      "1  1970s        5        7    2.800000  0.700000   0.201463        1   \n",
      "2  1980s        2        1    1.000000  1.000000   0.000000        1   \n",
      "3  1990s       78     1143   29.307692  0.380619   0.058971        1   \n",
      "4  2000s      195     5959   61.117949  0.315041   0.010425        1   \n",
      "5  2010s      137     2682   39.153285  0.287892   0.012263        1   \n",
      "6  2020s       73      568   15.561644  0.216134   0.085273        1   \n",
      "\n",
      "   largest_comp  diameter  avg_shortest  \n",
      "0             9         3      1.638889  \n",
      "1             5         2      1.300000  \n",
      "2             2         1      1.000000  \n",
      "3            78         3      1.646021  \n",
      "4           195         4      1.727465  \n",
      "5           137         3      1.761271  \n",
      "6            73         4      1.973744  \n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for decade, G in artist_graphs_peak.items():\n",
    "    if G.number_of_nodes()==0:\n",
    "        continue\n",
    "\n",
    "    comps = list(nx.connected_components(G))\n",
    "    largest = max(comps, key=len)\n",
    "    G0 = G.subgraph(largest)\n",
    "\n",
    "    rows.append({\n",
    "        \"decade\": decade,\n",
    "        \"n_nodes\":       G.number_of_nodes(),\n",
    "        \"n_edges\":       G.number_of_edges(),\n",
    "        \"avg_degree\":    sum(dict(G.degree()).values())/G.number_of_nodes(),\n",
    "        \"density\":       nx.density(G),\n",
    "        \"avg_clust\":     nx.average_clustering(G, weight=\"weight\"),\n",
    "        \"n_comps\":       nx.number_connected_components(G),\n",
    "        \"largest_comp\":  len(largest),\n",
    "        \"diameter\":      nx.diameter(G0) if G0.number_of_nodes()>1 else 0,\n",
    "        \"avg_shortest\":  nx.average_shortest_path_length(G0) if G0.number_of_nodes()>1 else 0\n",
    "    })\n",
    "\n",
    "stats_df = pd.DataFrame(rows)\n",
    "stats_df.to_csv(\"network_summary_per_decade.csv\", index=False)\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3d845f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Indlæs kun de kolonner, du behøver\n",
    "artist_lookup = pd.read_csv(\n",
    "    '../../datadump/artists_all.csv',\n",
    "    usecols=['artist_mbid', 'name'],\n",
    "    dtype=str\n",
    ")\n",
    "\n",
    "# Lav dict: mbid → navn\n",
    "artist_dict = artist_lookup.set_index('artist_mbid')['name'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8586c0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    decade      measure                           artist_mbid  \\\n",
      "0    1960s       degree  e7495426-6e14-4429-b647-dbe700ad57d4   \n",
      "1    1960s       degree  a85c70af-90e4-4a7c-83b1-e1bd567d7d2f   \n",
      "2    1960s       degree  812e18ca-29c2-472f-a185-b85befd03221   \n",
      "3    1960s       degree  bc4ca610-333b-424b-8c3c-c724e6327b62   \n",
      "4    1960s       degree  b411483b-e9cc-4b4f-9661-0452333c615a   \n",
      "..     ...          ...                                   ...   \n",
      "123  2020s  eigenvector  272989c8-5535-492d-a25c-9f58803e027f   \n",
      "124  2020s  eigenvector  6f1a58bf-9b1b-49cf-a44a-6cefad7ae04f   \n",
      "125  2020s  eigenvector  5df62a88-cac9-490a-b62c-c7c88f4020f4   \n",
      "126  2020s  eigenvector  b1e26560-60e5-4236-bbdb-9aa5a8d5ee19   \n",
      "127  2020s  eigenvector  b7539c32-53e7-4908-bda3-81449c367da6   \n",
      "\n",
      "                   artist_name  centrality  \n",
      "0               Joanie Sommers    0.875000  \n",
      "1              Bobby Goldsboro    0.750000  \n",
      "2                   Jimmy Dean    0.375000  \n",
      "3                   Peter Nero    0.375000  \n",
      "4    The New Christy Minstrels    0.375000  \n",
      "..                         ...         ...  \n",
      "123                        SZA    0.370396  \n",
      "124                   Dua Lipa    0.338859  \n",
      "125                   Doja Cat    0.304265  \n",
      "126                Post Malone    0.273219  \n",
      "127               Lana Del Rey    0.226799  \n",
      "\n",
      "[128 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# ── antag at du allerede har defineret: ────────────────────────────────────\n",
    "#   artist_graphs: {'1960s': G_1960s, '1970s': G_1970s, …}\n",
    "#   artist_dict:   mapping fra artist_mbid → artistnavn\n",
    "\n",
    "rows = []\n",
    "for decade, G in artist_graphs_peak.items():\n",
    "    if G.number_of_nodes() == 0:\n",
    "        continue\n",
    "    # Beregn centraliteter\n",
    "    deg_cent = nx.degree_centrality(G)\n",
    "    btw_cent = nx.betweenness_centrality(G, weight='weight')\n",
    "    cls_cent = nx.closeness_centrality(G)\n",
    "    eig_cent = nx.eigenvector_centrality(G, weight='weight', max_iter=500)\n",
    "\n",
    "    measures = [\n",
    "        ('degree',       deg_cent),\n",
    "        ('betweenness',  btw_cent),\n",
    "        ('closeness',    cls_cent),\n",
    "        ('eigenvector',  eig_cent),\n",
    "    ]\n",
    "\n",
    "    # For hver måltype: tag top 5 og gem i en tabel\n",
    "    for name, cent in measures:\n",
    "        top5 = sorted(cent.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        for mbid, score in top5:\n",
    "            rows.append({\n",
    "                'decade':        decade,\n",
    "                'measure':       name,\n",
    "                'artist_mbid':   mbid,\n",
    "                'artist_name':   artist_dict.get(mbid, mbid),\n",
    "                'centrality':    score\n",
    "            })\n",
    "\n",
    "# Lav en DataFrame og gem til CSV\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv('centrality_top5_per_decade.csv', index=False, encoding='utf-8')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eef0c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>measure</th>\n",
       "      <th colspan=\"2\" halign=\"left\">betweenness</th>\n",
       "      <th colspan=\"2\" halign=\"left\">closeness</th>\n",
       "      <th colspan=\"2\" halign=\"left\">degree</th>\n",
       "      <th colspan=\"2\" halign=\"left\">eigenvector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th>artists</th>\n",
       "      <th>scores</th>\n",
       "      <th>artists</th>\n",
       "      <th>scores</th>\n",
       "      <th>artists</th>\n",
       "      <th>scores</th>\n",
       "      <th>artists</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960s</th>\n",
       "      <td>Bobby Goldsboro, Joanie Sommers, Peter Nero, A...</td>\n",
       "      <td>0.429, 0.411, 0.250, 0.250, 0.161</td>\n",
       "      <td>Joanie Sommers, Bobby Goldsboro, Jimmy Dean, P...</td>\n",
       "      <td>0.889, 0.800, 0.615, 0.615, 0.615</td>\n",
       "      <td>Joanie Sommers, Bobby Goldsboro, Jimmy Dean, P...</td>\n",
       "      <td>0.875, 0.750, 0.375, 0.375, 0.375</td>\n",
       "      <td>Joanie Sommers, Peter Nero, Morgana King, Jimm...</td>\n",
       "      <td>0.653, 0.528, 0.438, 0.223, 0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970s</th>\n",
       "      <td>Shaun Cassidy, Jeannie C. Riley, The Partridge...</td>\n",
       "      <td>0.500, 0.333, 0.000, 0.000, 0.000</td>\n",
       "      <td>Lynn Anderson, Shaun Cassidy, Jeannie C. Riley...</td>\n",
       "      <td>1.000, 0.800, 0.800, 0.667, 0.667</td>\n",
       "      <td>Lynn Anderson, Shaun Cassidy, Jeannie C. Riley...</td>\n",
       "      <td>1.000, 0.750, 0.750, 0.500, 0.500</td>\n",
       "      <td>Lynn Anderson, Jeannie C. Riley, Loggins &amp; Mes...</td>\n",
       "      <td>0.688, 0.609, 0.266, 0.244, 0.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980s</th>\n",
       "      <td>Sheena Easton, Amy Holland</td>\n",
       "      <td>0.000, 0.000</td>\n",
       "      <td>Sheena Easton, Amy Holland</td>\n",
       "      <td>1.000, 1.000</td>\n",
       "      <td>Sheena Easton, Amy Holland</td>\n",
       "      <td>1.000, 1.000</td>\n",
       "      <td>Sheena Easton, Amy Holland</td>\n",
       "      <td>0.707, 0.707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990s</th>\n",
       "      <td>Bobby McFerrin, Janis Joplin, Neil Diamond, Bl...</td>\n",
       "      <td>0.063, 0.054, 0.042, 0.039, 0.038</td>\n",
       "      <td>Neil Diamond, Anne Murray, Kenny Rogers, Célin...</td>\n",
       "      <td>0.828, 0.819, 0.811, 0.802, 0.794</td>\n",
       "      <td>Neil Diamond, Anne Murray, Kenny Rogers, Célin...</td>\n",
       "      <td>0.792, 0.779, 0.766, 0.753, 0.740</td>\n",
       "      <td>Kenny Rogers, Anne Murray, Neil Diamond, Shirl...</td>\n",
       "      <td>0.351, 0.337, 0.327, 0.317, 0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000s</th>\n",
       "      <td>Corinne Bailey Rae, Santana, Meat Loaf, Duffy,...</td>\n",
       "      <td>0.035, 0.028, 0.024, 0.023, 0.022</td>\n",
       "      <td>Diana Ross, Barry Manilow, Tom Jones, Eric Cla...</td>\n",
       "      <td>0.812, 0.802, 0.802, 0.785, 0.764</td>\n",
       "      <td>Diana Ross, Barry Manilow, Tom Jones, Eric Cla...</td>\n",
       "      <td>0.768, 0.758, 0.753, 0.727, 0.696</td>\n",
       "      <td>Frank Sinatra, Nat King Cole, Louis Armstrong,...</td>\n",
       "      <td>0.415, 0.352, 0.314, 0.291, 0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010s</th>\n",
       "      <td>John Legend, Ed Sheeran, Bruce Springsteen, Ri...</td>\n",
       "      <td>0.032, 0.031, 0.030, 0.027, 0.026</td>\n",
       "      <td>Ed Sheeran, Bruce Springsteen, Johnny Mathis, ...</td>\n",
       "      <td>0.791, 0.773, 0.768, 0.764, 0.756</td>\n",
       "      <td>Ed Sheeran, Bruce Springsteen, Johnny Mathis, ...</td>\n",
       "      <td>0.735, 0.706, 0.699, 0.691, 0.676</td>\n",
       "      <td>Johnny Mathis, Tony Bennett, Dionne Warwick, H...</td>\n",
       "      <td>0.429, 0.389, 0.302, 0.219, 0.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020s</th>\n",
       "      <td>Taylor Swift, Lana Del Rey, Chicago, Luke Comb...</td>\n",
       "      <td>0.127, 0.108, 0.063, 0.059, 0.055</td>\n",
       "      <td>Taylor Swift, Lana Del Rey, Dua Lipa, SZA, Pos...</td>\n",
       "      <td>0.699, 0.692, 0.679, 0.661, 0.655</td>\n",
       "      <td>Lana Del Rey, Taylor Swift, Dua Lipa, SZA, Pos...</td>\n",
       "      <td>0.583, 0.583, 0.556, 0.528, 0.472</td>\n",
       "      <td>SZA, Dua Lipa, Doja Cat, Post Malone, Lana Del...</td>\n",
       "      <td>0.370, 0.339, 0.304, 0.273, 0.227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "measure                                        betweenness  \\\n",
       "type                                               artists   \n",
       "decade                                                       \n",
       "1960s    Bobby Goldsboro, Joanie Sommers, Peter Nero, A...   \n",
       "1970s    Shaun Cassidy, Jeannie C. Riley, The Partridge...   \n",
       "1980s                           Sheena Easton, Amy Holland   \n",
       "1990s    Bobby McFerrin, Janis Joplin, Neil Diamond, Bl...   \n",
       "2000s    Corinne Bailey Rae, Santana, Meat Loaf, Duffy,...   \n",
       "2010s    John Legend, Ed Sheeran, Bruce Springsteen, Ri...   \n",
       "2020s    Taylor Swift, Lana Del Rey, Chicago, Luke Comb...   \n",
       "\n",
       "measure                                     \\\n",
       "type                                scores   \n",
       "decade                                       \n",
       "1960s    0.429, 0.411, 0.250, 0.250, 0.161   \n",
       "1970s    0.500, 0.333, 0.000, 0.000, 0.000   \n",
       "1980s                         0.000, 0.000   \n",
       "1990s    0.063, 0.054, 0.042, 0.039, 0.038   \n",
       "2000s    0.035, 0.028, 0.024, 0.023, 0.022   \n",
       "2010s    0.032, 0.031, 0.030, 0.027, 0.026   \n",
       "2020s    0.127, 0.108, 0.063, 0.059, 0.055   \n",
       "\n",
       "measure                                          closeness  \\\n",
       "type                                               artists   \n",
       "decade                                                       \n",
       "1960s    Joanie Sommers, Bobby Goldsboro, Jimmy Dean, P...   \n",
       "1970s    Lynn Anderson, Shaun Cassidy, Jeannie C. Riley...   \n",
       "1980s                           Sheena Easton, Amy Holland   \n",
       "1990s    Neil Diamond, Anne Murray, Kenny Rogers, Célin...   \n",
       "2000s    Diana Ross, Barry Manilow, Tom Jones, Eric Cla...   \n",
       "2010s    Ed Sheeran, Bruce Springsteen, Johnny Mathis, ...   \n",
       "2020s    Taylor Swift, Lana Del Rey, Dua Lipa, SZA, Pos...   \n",
       "\n",
       "measure                                     \\\n",
       "type                                scores   \n",
       "decade                                       \n",
       "1960s    0.889, 0.800, 0.615, 0.615, 0.615   \n",
       "1970s    1.000, 0.800, 0.800, 0.667, 0.667   \n",
       "1980s                         1.000, 1.000   \n",
       "1990s    0.828, 0.819, 0.811, 0.802, 0.794   \n",
       "2000s    0.812, 0.802, 0.802, 0.785, 0.764   \n",
       "2010s    0.791, 0.773, 0.768, 0.764, 0.756   \n",
       "2020s    0.699, 0.692, 0.679, 0.661, 0.655   \n",
       "\n",
       "measure                                             degree  \\\n",
       "type                                               artists   \n",
       "decade                                                       \n",
       "1960s    Joanie Sommers, Bobby Goldsboro, Jimmy Dean, P...   \n",
       "1970s    Lynn Anderson, Shaun Cassidy, Jeannie C. Riley...   \n",
       "1980s                           Sheena Easton, Amy Holland   \n",
       "1990s    Neil Diamond, Anne Murray, Kenny Rogers, Célin...   \n",
       "2000s    Diana Ross, Barry Manilow, Tom Jones, Eric Cla...   \n",
       "2010s    Ed Sheeran, Bruce Springsteen, Johnny Mathis, ...   \n",
       "2020s    Lana Del Rey, Taylor Swift, Dua Lipa, SZA, Pos...   \n",
       "\n",
       "measure                                     \\\n",
       "type                                scores   \n",
       "decade                                       \n",
       "1960s    0.875, 0.750, 0.375, 0.375, 0.375   \n",
       "1970s    1.000, 0.750, 0.750, 0.500, 0.500   \n",
       "1980s                         1.000, 1.000   \n",
       "1990s    0.792, 0.779, 0.766, 0.753, 0.740   \n",
       "2000s    0.768, 0.758, 0.753, 0.727, 0.696   \n",
       "2010s    0.735, 0.706, 0.699, 0.691, 0.676   \n",
       "2020s    0.583, 0.583, 0.556, 0.528, 0.472   \n",
       "\n",
       "measure                                        eigenvector  \\\n",
       "type                                               artists   \n",
       "decade                                                       \n",
       "1960s    Joanie Sommers, Peter Nero, Morgana King, Jimm...   \n",
       "1970s    Lynn Anderson, Jeannie C. Riley, Loggins & Mes...   \n",
       "1980s                           Sheena Easton, Amy Holland   \n",
       "1990s    Kenny Rogers, Anne Murray, Neil Diamond, Shirl...   \n",
       "2000s    Frank Sinatra, Nat King Cole, Louis Armstrong,...   \n",
       "2010s    Johnny Mathis, Tony Bennett, Dionne Warwick, H...   \n",
       "2020s    SZA, Dua Lipa, Doja Cat, Post Malone, Lana Del...   \n",
       "\n",
       "measure                                     \n",
       "type                                scores  \n",
       "decade                                      \n",
       "1960s    0.653, 0.528, 0.438, 0.223, 0.187  \n",
       "1970s    0.688, 0.609, 0.266, 0.244, 0.159  \n",
       "1980s                         0.707, 0.707  \n",
       "1990s    0.351, 0.337, 0.327, 0.317, 0.220  \n",
       "2000s    0.415, 0.352, 0.314, 0.291, 0.267  \n",
       "2010s    0.429, 0.389, 0.302, 0.219, 0.211  \n",
       "2020s    0.370, 0.339, 0.304, 0.273, 0.227  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# antag at df er den DataFrame du allerede har med kolonner:\n",
    "# ['decade','measure','artist_name','centrality']\n",
    "\n",
    "# 1) Lav to pivottabeller: én med navne, én med scores\n",
    "names = (\n",
    "    df\n",
    "    .groupby(['decade','measure'])['artist_name']\n",
    "    .apply(lambda x: \", \".join(x))\n",
    "    .unstack()\n",
    ")\n",
    "scores = (\n",
    "    df\n",
    "    .groupby(['decade','measure'])['centrality']\n",
    "    .apply(lambda x: \", \".join(f\"{v:.3f}\" for v in x))\n",
    "    .unstack()\n",
    ")\n",
    "\n",
    "# 2) Sæt dem sammen i én DataFrame med multi‐level kolonner\n",
    "out = pd.concat([names, scores], axis=1, keys=['artists','scores'])\n",
    "out.columns = pd.MultiIndex.from_product(\n",
    "    out.columns.levels,\n",
    "    names=['type','measure']\n",
    ")\n",
    "\n",
    "# 3) (Valgfrit) Ryk type først, så mål\n",
    "out = out.swaplevel(axis=1).sort_index(axis=1, level=0)\n",
    "\n",
    "# 4) Gem eller vis\n",
    "out.to_csv('centrality_top5_pivot.csv', encoding='utf-8')\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59f82721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josefinevoglhofer/Library/Python/3.9/lib/python/site-packages/networkx/algorithms/assortativity/correlation.py:302: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return (xy * (M - ab)).sum() / np.sqrt(vara * varb)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "      <th>avg_degree</th>\n",
       "      <th>median_degree</th>\n",
       "      <th>degree_gini</th>\n",
       "      <th>density</th>\n",
       "      <th>avg_clustering</th>\n",
       "      <th>assortativity_deg</th>\n",
       "      <th>avg_path_length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>n_communities</th>\n",
       "      <th>modularity</th>\n",
       "      <th>top_writers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decade</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1960s</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>3.333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.589</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>1.639</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222</td>\n",
       "      <td>e7495426-6e14-4429-b647-dbe700ad57d4:27, bc4ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970s</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2.800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.767</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>1.300</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>354812d4-2dfb-4611-9a8f-8f8e795e48bf:33, 79251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980s</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7b004920-b04e-4ff2-b2e5-55d8f1cc0522:4, 8439a3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990s</th>\n",
       "      <td>78</td>\n",
       "      <td>1143</td>\n",
       "      <td>29.308</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.743</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>1.646</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.086</td>\n",
       "      <td>c3d14b41-a48d-488f-bfed-ce0597bb0b1f:437, 05ec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000s</th>\n",
       "      <td>195</td>\n",
       "      <td>5959</td>\n",
       "      <td>61.118</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.718</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>1.727</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.141</td>\n",
       "      <td>197450cd-0124-4164-b723-3c22dd16494d:2260, fbe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010s</th>\n",
       "      <td>137</td>\n",
       "      <td>2682</td>\n",
       "      <td>39.153</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.288</td>\n",
       "      <td>0.686</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>1.761</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.282</td>\n",
       "      <td>48896dee-a985-424d-9849-84802f7e79c9:900, 8be0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020s</th>\n",
       "      <td>73</td>\n",
       "      <td>568</td>\n",
       "      <td>15.562</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.597</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>1.974</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.214</td>\n",
       "      <td>6f1a58bf-9b1b-49cf-a44a-6cefad7ae04f:139, 2729...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        nodes  edges  avg_degree  median_degree  degree_gini  density  \\\n",
       "decade                                                                  \n",
       "1960s       9     15       3.333            3.0        0.281    0.417   \n",
       "1970s       5      7       2.800            3.0        0.143    0.700   \n",
       "1980s       2      1       1.000            1.0        0.000    1.000   \n",
       "1990s      78   1143      29.308           30.5        0.334    0.381   \n",
       "2000s     195   5959      61.118           58.0        0.372    0.315   \n",
       "2010s     137   2682      39.153           35.0        0.353    0.288   \n",
       "2020s      73    568      15.562           15.0        0.379    0.216   \n",
       "\n",
       "        avg_clustering  assortativity_deg  avg_path_length  diameter  \\\n",
       "decade                                                                 \n",
       "1960s            0.589             -0.558            1.639         3   \n",
       "1970s            0.767             -0.500            1.300         2   \n",
       "1980s            0.000                NaN            1.000         1   \n",
       "1990s            0.743             -0.200            1.646         3   \n",
       "2000s            0.718             -0.162            1.727         4   \n",
       "2010s            0.686             -0.142            1.761         3   \n",
       "2020s            0.597             -0.110            1.974         4   \n",
       "\n",
       "        n_communities  modularity  \\\n",
       "decade                              \n",
       "1960s               2       0.222   \n",
       "1970s               2      -0.219   \n",
       "1980s               1       0.000   \n",
       "1990s               3       0.086   \n",
       "2000s               3       0.141   \n",
       "2010s               3       0.282   \n",
       "2020s               3       0.214   \n",
       "\n",
       "                                              top_writers  \n",
       "decade                                                     \n",
       "1960s   e7495426-6e14-4429-b647-dbe700ad57d4:27, bc4ca...  \n",
       "1970s   354812d4-2dfb-4611-9a8f-8f8e795e48bf:33, 79251...  \n",
       "1980s   7b004920-b04e-4ff2-b2e5-55d8f1cc0522:4, 8439a3...  \n",
       "1990s   c3d14b41-a48d-488f-bfed-ce0597bb0b1f:437, 05ec...  \n",
       "2000s   197450cd-0124-4164-b723-3c22dd16494d:2260, fbe...  \n",
       "2010s   48896dee-a985-424d-9849-84802f7e79c9:900, 8be0...  \n",
       "2020s   6f1a58bf-9b1b-49cf-a44a-6cefad7ae04f:139, 2729...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# ---------- helpers ---------------------------------------------------\n",
    "def gini(array):\n",
    "    \"\"\"Gini coefficient for inequality of degree distribution.\"\"\"\n",
    "    if len(array) == 0:\n",
    "        return np.nan\n",
    "    array = np.sort(np.array(array, dtype=float))\n",
    "    n = len(array)\n",
    "    cum = np.cumsum(array)\n",
    "    return (n + 1 - 2 * cum.sum() / cum[-1]) / n\n",
    "\n",
    "def safe_metric(func, *args, **kwargs):\n",
    "    \"\"\"Return NaN instead of blowing up on disconnected graphs.\"\"\"\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except (nx.NetworkXError, ZeroDivisionError):\n",
    "        return np.nan\n",
    "\n",
    "# ---------- what we want to measure ----------------------------------\n",
    "def decade_metrics(G, top_n=5):\n",
    "    \"\"\"\n",
    "    Compute a dictionary of graph statistics that are easy to interpret\n",
    "    in a social-science write-up.\n",
    "    \"\"\"\n",
    "    n = G.number_of_nodes()\n",
    "    m = G.number_of_edges()\n",
    "    deg   = dict(G.degree())\n",
    "    deg_w = dict(G.degree(weight=\"weight\"))\n",
    "    degrees = np.array(list(deg.values()))\n",
    "\n",
    "    # giant component for path-based metrics\n",
    "    if n > 0:\n",
    "        GCC = max(nx.connected_components(G), key=len)\n",
    "        sub = G.subgraph(GCC)\n",
    "    else:\n",
    "        sub = G\n",
    "\n",
    "    return {\n",
    "        \"nodes\"             : n,\n",
    "        \"edges\"             : m,\n",
    "        \"avg_degree\"        : degrees.mean()          if n else np.nan,\n",
    "        \"median_degree\"     : np.median(degrees)      if n else np.nan,\n",
    "        \"degree_gini\"       : gini(degrees),          # inequality measure\n",
    "        \"density\"           : nx.density(G),\n",
    "        \"avg_clustering\"    : safe_metric(nx.average_clustering, G, weight=None),\n",
    "        \"assortativity_deg\" : safe_metric(nx.degree_assortativity_coefficient, G),\n",
    "        \"avg_path_length\"   : safe_metric(nx.average_shortest_path_length, sub),\n",
    "        \"diameter\"          : safe_metric(nx.diameter, sub),\n",
    "        # ---- community detection (greedy modularity) ----\n",
    "        **{\n",
    "            \"n_communities\": len(comms := list(nx.algorithms.community.greedy_modularity_communities(G))),\n",
    "            \"modularity\"   : nx.algorithms.community.modularity(G, comms)\n",
    "        },\n",
    "        # top-N weighted-degree writers for slide copy\n",
    "        \"top_writers\"       : \", \".join(\n",
    "            f\"{wid}:{int(deg_w[wid])}\"\n",
    "            for wid, _ in Counter(deg_w).most_common(top_n)\n",
    "        )\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 1. RUN over all decades\n",
    "# ---------------------------------------------------------------------\n",
    "records = []\n",
    "for decade, G in artist_graphs_peak.items():\n",
    "    if G.number_of_nodes() == 0:\n",
    "        print(f\"Skipping null graph for {decade}\")\n",
    "        continue\n",
    "    rec = decade_metrics(G)\n",
    "    rec[\"decade\"] = decade\n",
    "    records.append(rec)\n",
    "\n",
    "metrics_df = (pd.DataFrame(records)\n",
    "                .sort_values(\"decade\")\n",
    "                .set_index(\"decade\")\n",
    "                .round(3))\n",
    "\n",
    "display(metrics_df)          # Jupyter display; or print(metrics_df)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2. OPTIONAL – export for website / slides\n",
    "# ---------------------------------------------------------------------\n",
    "metrics_df.to_csv(\"decade_network_metrics_flest_udgivelser.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4738e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
